{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the tactile gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jan 20 2023 16:26:58\n"
     ]
    }
   ],
   "source": [
    "from tactile_gym.rl_envs.demo_rl_env_base import demo_rl_env\n",
    "from tactile_gym.rl_envs.exploration.edge_follow.edge_follow_env import EdgeFollowEnv\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import random as rnd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up some variables of what we want within the envirnment. \n",
    "\n",
    "Number of iterations is how long our training loop will be\n",
    "\n",
    "max_steps is how many steps each iteration can ake within the environment\n",
    "\n",
    "show_gui allows us to view or not view a gui showing whats going on\n",
    "\n",
    "This is the same with show tactle\n",
    "\n",
    "Rendering is required for showing the gui - it is quicker without\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = int(0)\n",
    "num_iter = 100\n",
    "max_steps = 250\n",
    "show_gui = True\n",
    "show_tactile = True\n",
    "render = True\n",
    "print_info = False\n",
    "image_size = [128, 128]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=3\n",
      "argv[0] = --unused\n",
      "argv[1] = \n",
      "argv[2] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Mesa/X.org\n",
      "GL_RENDERER=llvmpipe (LLVM 12.0.0, 256 bits)\n",
      "GL_VERSION=4.5 (Core Profile) Mesa 21.2.6\n",
      "GL_SHADING_LANGUAGE_VERSION=4.50\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.5 (Core Profile) Mesa 21.2.6\n",
      "Vendor = Mesa/X.org\n",
      "Renderer = llvmpipe (LLVM 12.0.0, 256 bits)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Mesa/X.org\n",
      "ven = Mesa/X.org\n"
     ]
    }
   ],
   "source": [
    "env_modes = {\n",
    "    # which dofs can have movement\n",
    "    \"movement_mode\": \"xy\",\n",
    "\n",
    "    # specify arm\n",
    "    \"arm_type\": \"ur5\",\n",
    "\n",
    "    # specify tactile sensor\n",
    "    \"tactile_sensor_name\": \"tactip\",\n",
    "    # \"tactile_sensor_name\": \"digit\",\n",
    "    # \"tactile_sensor_name\": \"digitac\",\n",
    "\n",
    "    # the type of control used\n",
    "    # \"control_mode\": \"TCP_position_control\",\n",
    "    'control_mode': 'TCP_velocity_control',\n",
    "\n",
    "    # add variation to embed distance to optimise for\n",
    "    # warning, don't use rand height when controlling z unless\n",
    "    # including embed distance in observation\n",
    "    # 'noise_mode':'fixed_height',\n",
    "    \"noise_mode\": \"rand_height\",\n",
    "\n",
    "    # which observation type to return\n",
    "    'observation_mode': 'oracle',\n",
    "    \"observation_mode\": \"tactile\",\n",
    "    # 'observation_mode':'visual',\n",
    "    # 'observation_mode':'visuotactile',\n",
    "\n",
    "    # which reward type to use (currently only dense)\n",
    "    \"reward_mode\": \"dense\"\n",
    "    # 'reward_mode':'sparse'\n",
    "}\n",
    "env = EdgeFollowEnv(\n",
    "    max_steps=max_steps,\n",
    "    env_modes=env_modes,\n",
    "    show_gui=show_gui,\n",
    "    show_tactile=show_tactile,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "# set seed for deterministic results\n",
    "env.seed(seed)\n",
    "env.action_space.np_random.seed(seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate GUI is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create controllable parameters on GUI\n",
    "action_ids = []\n",
    "min_action = env.min_action\n",
    "max_action = env.max_action\n",
    "if show_gui:\n",
    "\n",
    "    if env_modes[\"movement_mode\"] == \"xy\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "\n",
    "    elif env_modes[\"movement_mode\"] == \"xyz\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dZ\", min_action, max_action, 0))\n",
    "\n",
    "    elif env_modes[\"movement_mode\"] == \"xyRz\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dRz\", min_action, max_action, 0))\n",
    "\n",
    "    elif env_modes[\"movement_mode\"] == \"xyzRz\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dZ\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dRz\", min_action, max_action, 0))\n",
    "\n",
    "# run the control loop\n",
    "#demo_rl_env(env, num_iter, action_ids, show_gui, show_tactile, render, print_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make model for evolution, this uses a convolutional neural network. Weights are assigned randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_Conv2D:\n",
    "    def __init__(self, num_input, layers, num_output):\n",
    "        assert type(layers)==type([]), \"Error with layers, give array of the number of layers\"\n",
    "        self.num_input = num_input  #set input number\n",
    "        self.num_output = num_output #set ooutput number\n",
    "        self.hidden=[]\n",
    "        last=num_input\n",
    "        self.num_genes=0\n",
    "        for layer in layers:\n",
    "            self.hidden.append(layer)\n",
    "            self.num_genes+=(last * layer)\n",
    "            last=layer\n",
    "        self.num_genes +=(self.hidden[-1]*num_output)+num_output\n",
    "        self.weights = None\n",
    "        self.hidden_weights=None\n",
    "        self.bias = None\n",
    "        print(\"Auto\",self.num_genes)\n",
    "    def set_genes(self, gene):\n",
    "        weight_idxs = self.num_input * self.hidden[0] #size of weights to hidden\n",
    "        current=weight_idxs\n",
    "        weights_idxs=[current] #start with end of last\n",
    "        for i in range(len(self.hidden)-1):\n",
    "            current+=self.hidden[i]*self.hidden[i+1] #calculate next idx for each layer\n",
    "            weights_idxs.append(current)\n",
    "        bias_idxs=None\n",
    "        weights_idxs.append(self.hidden[-1] * self.num_output + weights_idxs[-1]) #add last layer heading to output\n",
    "        bias_idxs = weights_idxs[-1]+ self.num_output #sizes of biases\n",
    "        w = gene[0 : weight_idxs].reshape(self.hidden[0], self.num_input)   #merge genes\n",
    "        ws=[]\n",
    "        for i in range(len(self.hidden)-1):\n",
    "            ws.append(gene[weights_idxs[i] : weights_idxs[i+1]].reshape(self.hidden[i+1], self.hidden[i]))\n",
    "        ws.append(gene[weights_idxs[-2] : weights_idxs[-1]].reshape(self.num_output, self.hidden[-1]))\n",
    "        b = gene[weights_idxs[-1]: bias_idxs].reshape(self.num_output,) #merge genes\n",
    "\n",
    "        self.weights = torch.from_numpy(w) #assign weights\n",
    "        self.hidden_weights=[]\n",
    "        for w in ws:\n",
    "            self.hidden_weights.append(torch.from_numpy(w))\n",
    "        self.bias = torch.from_numpy(b) #assign biases\n",
    "\n",
    "    def forward(self, x):\n",
    "        #create conv layer\n",
    "        scharr = np.array([[ -3-3, 0-10,  +3 -3],\n",
    "                   [-10+0, 0+ 0, +10 +0],\n",
    "                   [ -3+3, 0+10,  +3 +3]]) # Gx + j*Gy\n",
    "        x= signal.convolve2d(x, scharr, boundary='symm', mode='same')   \n",
    "        x=x.flatten()\n",
    "        x=torch.tensor(x[:,np.newaxis]).float()  \n",
    "        #x = torch.tensor(np.dot(self.weights.float(),x).flatten()).float()\n",
    "        #run through forward layers\n",
    "        x = torch.mm(x.T, self.weights.T.float()) #first layer\n",
    "\n",
    "        for i in range(len(self.hidden_weights)-1):\n",
    "            x = torch.mm(x,self.hidden_weights[i].T.float()) #second layer\n",
    "        return torch.mm(x,self.hidden_weights[-1].T.float()) + self.bias #third layer\n",
    "    \n",
    "    def get_action(self, x,vec):\n",
    "        vec=np.array(vec)\n",
    "        vectors=[(1,1),(1,0),(0,1),(-1,-1),(-1,0),(0,-1),(-1,1),(1,-1)] #possible moves\n",
    "        arr=list(self.forward(x,vec)[0])\n",
    "        ind=np.argmax(arr)\n",
    "        return vectors[ind]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an agent and population of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto 1646262\n",
      "[7.895365 1.583937 -4.527666 ... 6.432388 6.104206 -3.224422]\n"
     ]
    }
   ],
   "source": [
    "sensor=Agent_Conv2D(128*128,[100,60,30],2)\n",
    "size=sensor.num_genes\n",
    "def gen_population(pop_size=100):\n",
    "    population=np.random.normal(0,3,(pop_size,size))\n",
    "    return population\n",
    "\"\"\"for i in range(pop_size):\n",
    "    population[i]+=(size))\"\"\"\n",
    "\n",
    "print(gen_population()[0])\n",
    "population=gen_population()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitness function and mutation of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(tactile):\n",
    "    #lets say we want to maximize the lighter pixels \n",
    "    all=np.sum(tactile)\n",
    "    all=(all/255)/(128*128)\n",
    "    return all\n",
    "def mutation(gene, mean=0, std=0.5,size=100):\n",
    "    assert size<len(gene)\n",
    "    n=rnd.randint(0,len(gene)-size-1)\n",
    "    array=np.random.normal(mean,std,size=size)\n",
    "    gene = gene[n:n+size] + array #mutate the gene via normal \n",
    "    # constraint\n",
    "    gene[gene >4] = 4\n",
    "    gene[gene < -4] = -4\n",
    "    return gene\n",
    "\n",
    "def crossover(loser, winner, p_crossover=0.5): #provide a crossover function\n",
    "    for i,gene in enumerate(winner):\n",
    "      if rnd.random() <= p_crossover:\n",
    "        loser[i] = winner[i]\n",
    "    return loser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a loop with a genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# collection loop\\nGENERATIONS=1000\\nr_sum = 0\\no, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\\nstep = 0\\nfor i in range(GENERATIONS):\\n        sensor.set_genes(population[0])\\n        tactile_input=np.reshape(o[\\'tactile\\'],(128,128))\\n        a=sensor.forward(tactile_input)[0] #push through tactile input into agent\\n        # step the environment\\n        o, r, d, info = env.step(a)\\n    \\n        # render visual + tactile observation\\n        if render:\\n            render_img = env.render()\\n        #print(o[\\'tactile\\'])\\n        r_sum += r\\n        step += 1\\n\\n        q_key = ord(\"q\")\\n        r_key = ord(\"r\")\\n        keys = env._pb.getKeyboardEvents()\\n        if q_key in keys and keys[q_key] & env._pb.KEY_WAS_TRIGGERED:\\n            exit()\\n        elif r_key in keys and keys[r_key] & env._pb.KEY_WAS_TRIGGERED:\\n            d = True\\n\\nprint(\"Total Reward: \", r_sum)\\n    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# collection loop\n",
    "GENERATIONS=1000\n",
    "r_sum = 0\n",
    "o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "step = 0\n",
    "for i in range(GENERATIONS):\n",
    "        sensor.set_genes(population[0])\n",
    "        tactile_input=np.reshape(o['tactile'],(128,128))\n",
    "        a=sensor.forward(tactile_input)[0] #push through tactile input into agent\n",
    "        # step the environment\n",
    "        o, r, d, info = env.step(a)\n",
    "    \n",
    "        # render visual + tactile observation\n",
    "        if render:\n",
    "            render_img = env.render()\n",
    "        #print(o['tactile'])\n",
    "        r_sum += r\n",
    "        step += 1\n",
    "\n",
    "        q_key = ord(\"q\")\n",
    "        r_key = ord(\"r\")\n",
    "        keys = env._pb.getKeyboardEvents()\n",
    "        if q_key in keys and keys[q_key] & env._pb.KEY_WAS_TRIGGERED:\n",
    "            exit()\n",
    "        elif r_key in keys and keys[r_key] & env._pb.KEY_WAS_TRIGGERED:\n",
    "            d = True\n",
    "\n",
    "print(\"Total Reward: \", r_sum)\n",
    "    \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the microbial GA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN:  0 FITNESS:  0\n",
      "GEN:  1 FITNESS:  0.008545639935661764\n",
      "GEN:  2 FITNESS:  0.008545639935661764\n",
      "GEN:  3 FITNESS:  0.008545639935661764\n",
      "GEN:  4 FITNESS:  0.01319125306372549\n",
      "GEN:  5 FITNESS:  0.01319125306372549\n",
      "GEN:  6 FITNESS:  0.01319125306372549\n",
      "GEN:  7 FITNESS:  0.01319125306372549\n",
      "GEN:  8 FITNESS:  0.01319125306372549\n",
      "GEN:  9 FITNESS:  0.01319125306372549\n",
      "GEN:  10 FITNESS:  0.01319125306372549\n",
      "GEN:  11 FITNESS:  0.01319125306372549\n",
      "GEN:  12 FITNESS:  0.014725988051470589\n",
      "GEN:  13 FITNESS:  0.014725988051470589\n",
      "GEN:  14 FITNESS:  0.014725988051470589\n",
      "GEN:  15 FITNESS:  0.025185499004289215\n",
      "GEN:  16 FITNESS:  0.025185499004289215\n",
      "GEN:  17 FITNESS:  0.025185499004289215\n",
      "GEN:  18 FITNESS:  0.025185499004289215\n",
      "GEN:  19 FITNESS:  0.025185499004289215\n",
      "GEN:  20 FITNESS:  0.025185499004289215\n",
      "GEN:  21 FITNESS:  0.025185499004289215\n",
      "GEN:  22 FITNESS:  0.025185499004289215\n",
      "GEN:  23 FITNESS:  0.025185499004289215\n",
      "GEN:  24 FITNESS:  0.025185499004289215\n",
      "GEN:  25 FITNESS:  0.025185499004289215\n",
      "GEN:  26 FITNESS:  0.025185499004289215\n",
      "GEN:  27 FITNESS:  0.025185499004289215\n",
      "GEN:  28 FITNESS:  0.025185499004289215\n",
      "GEN:  29 FITNESS:  0.025185499004289215\n",
      "GEN:  30 FITNESS:  0.025185499004289215\n",
      "GEN:  31 FITNESS:  0.025185499004289215\n",
      "GEN:  32 FITNESS:  0.025185499004289215\n",
      "GEN:  33 FITNESS:  0.025185499004289215\n",
      "GEN:  34 FITNESS:  0.025185499004289215\n",
      "GEN:  35 FITNESS:  0.025185499004289215\n",
      "GEN:  36 FITNESS:  0.025185499004289215\n",
      "GEN:  37 FITNESS:  0.025185499004289215\n",
      "GEN:  38 FITNESS:  0.025185499004289215\n",
      "GEN:  39 FITNESS:  0.025185499004289215\n",
      "GEN:  40 FITNESS:  0.025185499004289215\n",
      "GEN:  41 FITNESS:  0.025185499004289215\n",
      "GEN:  42 FITNESS:  0.025185499004289215\n",
      "GEN:  43 FITNESS:  0.025185499004289215\n",
      "GEN:  44 FITNESS:  0.025185499004289215\n",
      "GEN:  45 FITNESS:  0.025185499004289215\n",
      "GEN:  46 FITNESS:  0.025185499004289215\n",
      "GEN:  47 FITNESS:  0.025185499004289215\n",
      "GEN:  48 FITNESS:  0.025185499004289215\n",
      "GEN:  49 FITNESS:  0.025185499004289215\n",
      "GEN:  50 FITNESS:  0.025185499004289215\n",
      "GEN:  51 FITNESS:  0.025185499004289215\n",
      "GEN:  52 FITNESS:  0.025185499004289215\n",
      "GEN:  53 FITNESS:  0.025185499004289215\n",
      "GEN:  54 FITNESS:  0.025185499004289215\n",
      "GEN:  55 FITNESS:  0.025185499004289215\n",
      "GEN:  56 FITNESS:  0.025185499004289215\n",
      "GEN:  57 FITNESS:  0.025185499004289215\n",
      "GEN:  58 FITNESS:  0.025185499004289215\n",
      "GEN:  59 FITNESS:  0.025185499004289215\n",
      "GEN:  60 FITNESS:  0.025185499004289215\n",
      "GEN:  61 FITNESS:  0.025185499004289215\n",
      "GEN:  62 FITNESS:  0.025185499004289215\n",
      "GEN:  63 FITNESS:  0.025185499004289215\n",
      "GEN:  64 FITNESS:  0.025185499004289215\n",
      "GEN:  65 FITNESS:  0.025185499004289215\n",
      "GEN:  66 FITNESS:  0.025185499004289215\n",
      "GEN:  67 FITNESS:  0.025185499004289215\n",
      "GEN:  68 FITNESS:  0.0318570006127451\n",
      "GEN:  69 FITNESS:  0.0318570006127451\n",
      "GEN:  70 FITNESS:  0.0318570006127451\n",
      "GEN:  71 FITNESS:  0.0318570006127451\n",
      "GEN:  72 FITNESS:  0.0318570006127451\n",
      "GEN:  73 FITNESS:  0.0318570006127451\n",
      "GEN:  74 FITNESS:  0.0318570006127451\n",
      "GEN:  75 FITNESS:  0.0318570006127451\n",
      "GEN:  76 FITNESS:  0.0318570006127451\n",
      "GEN:  77 FITNESS:  0.0318570006127451\n",
      "GEN:  78 FITNESS:  0.0318570006127451\n",
      "GEN:  79 FITNESS:  0.0318570006127451\n",
      "GEN:  80 FITNESS:  0.0318570006127451\n",
      "GEN:  81 FITNESS:  0.0318570006127451\n",
      "GEN:  82 FITNESS:  0.0318570006127451\n",
      "GEN:  83 FITNESS:  0.0318570006127451\n",
      "GEN:  84 FITNESS:  0.0318570006127451\n",
      "GEN:  85 FITNESS:  0.0318570006127451\n",
      "GEN:  86 FITNESS:  0.0318570006127451\n",
      "GEN:  87 FITNESS:  0.0318570006127451\n",
      "GEN:  88 FITNESS:  0.0318570006127451\n",
      "GEN:  89 FITNESS:  0.0318570006127451\n",
      "GEN:  90 FITNESS:  0.0318570006127451\n",
      "GEN:  91 FITNESS:  0.0318570006127451\n",
      "GEN:  92 FITNESS:  0.0318570006127451\n",
      "GEN:  93 FITNESS:  0.0318570006127451\n",
      "GEN:  94 FITNESS:  0.0318570006127451\n",
      "GEN:  95 FITNESS:  0.0318570006127451\n",
      "GEN:  96 FITNESS:  0.0318570006127451\n",
      "GEN:  97 FITNESS:  0.0318570006127451\n",
      "GEN:  98 FITNESS:  0.0318570006127451\n",
      "GEN:  99 FITNESS:  0.0318570006127451\n",
      "GEN:  100 FITNESS:  0.0318570006127451\n",
      "GEN:  101 FITNESS:  0.0318570006127451\n",
      "GEN:  102 FITNESS:  0.0318570006127451\n",
      "GEN:  103 FITNESS:  0.0318570006127451\n",
      "GEN:  104 FITNESS:  0.0318570006127451\n",
      "GEN:  105 FITNESS:  0.0318570006127451\n",
      "GEN:  106 FITNESS:  0.0318570006127451\n",
      "GEN:  107 FITNESS:  0.0318570006127451\n",
      "GEN:  108 FITNESS:  0.0318570006127451\n",
      "GEN:  109 FITNESS:  0.0318570006127451\n",
      "GEN:  110 FITNESS:  0.0318570006127451\n",
      "GEN:  111 FITNESS:  0.0318570006127451\n",
      "GEN:  112 FITNESS:  0.0318570006127451\n",
      "GEN:  113 FITNESS:  0.0318570006127451\n",
      "GEN:  114 FITNESS:  0.0318570006127451\n",
      "GEN:  115 FITNESS:  0.0318570006127451\n",
      "GEN:  116 FITNESS:  0.0318570006127451\n",
      "GEN:  117 FITNESS:  0.0318570006127451\n",
      "GEN:  118 FITNESS:  0.0318570006127451\n",
      "GEN:  119 FITNESS:  0.0318570006127451\n",
      "GEN:  120 FITNESS:  0.0318570006127451\n",
      "GEN:  121 FITNESS:  0.0318570006127451\n",
      "GEN:  122 FITNESS:  0.0318570006127451\n",
      "GEN:  123 FITNESS:  0.0318570006127451\n",
      "GEN:  124 FITNESS:  0.0318570006127451\n",
      "GEN:  125 FITNESS:  0.0318570006127451\n",
      "GEN:  126 FITNESS:  0.0318570006127451\n",
      "GEN:  127 FITNESS:  0.0318570006127451\n",
      "GEN:  128 FITNESS:  0.0318570006127451\n",
      "GEN:  129 FITNESS:  0.0318570006127451\n",
      "GEN:  130 FITNESS:  0.0318570006127451\n",
      "GEN:  131 FITNESS:  0.0318570006127451\n",
      "GEN:  132 FITNESS:  0.0318570006127451\n",
      "GEN:  133 FITNESS:  0.0318570006127451\n",
      "GEN:  134 FITNESS:  0.0318570006127451\n",
      "GEN:  135 FITNESS:  0.0318570006127451\n",
      "GEN:  136 FITNESS:  0.0318570006127451\n",
      "GEN:  137 FITNESS:  0.0318570006127451\n",
      "GEN:  138 FITNESS:  0.0318570006127451\n",
      "GEN:  139 FITNESS:  0.0318570006127451\n",
      "GEN:  140 FITNESS:  0.0318570006127451\n",
      "GEN:  141 FITNESS:  0.0318570006127451\n",
      "GEN:  142 FITNESS:  0.0318570006127451\n",
      "GEN:  143 FITNESS:  0.0318570006127451\n",
      "GEN:  144 FITNESS:  0.0318570006127451\n",
      "GEN:  145 FITNESS:  0.0318570006127451\n",
      "GEN:  146 FITNESS:  0.0318570006127451\n",
      "GEN:  147 FITNESS:  0.0318570006127451\n",
      "GEN:  148 FITNESS:  0.0318570006127451\n",
      "GEN:  149 FITNESS:  0.0318570006127451\n",
      "GEN:  150 FITNESS:  0.0318570006127451\n",
      "GEN:  151 FITNESS:  0.0318570006127451\n",
      "GEN:  152 FITNESS:  0.0318570006127451\n",
      "GEN:  153 FITNESS:  0.0318570006127451\n",
      "GEN:  154 FITNESS:  0.0318570006127451\n",
      "GEN:  155 FITNESS:  0.0318570006127451\n",
      "GEN:  156 FITNESS:  0.0318570006127451\n",
      "GEN:  157 FITNESS:  0.0318570006127451\n",
      "GEN:  158 FITNESS:  0.0318570006127451\n",
      "GEN:  159 FITNESS:  0.0318570006127451\n",
      "GEN:  160 FITNESS:  0.0318570006127451\n",
      "GEN:  161 FITNESS:  0.0318570006127451\n",
      "GEN:  162 FITNESS:  0.0318570006127451\n",
      "GEN:  163 FITNESS:  0.0318570006127451\n",
      "GEN:  164 FITNESS:  0.0318570006127451\n",
      "GEN:  165 FITNESS:  0.0318570006127451\n",
      "GEN:  166 FITNESS:  0.0318570006127451\n",
      "GEN:  167 FITNESS:  0.0318570006127451\n",
      "GEN:  168 FITNESS:  0.0318570006127451\n",
      "GEN:  169 FITNESS:  0.0318570006127451\n",
      "GEN:  170 FITNESS:  0.0318570006127451\n",
      "GEN:  171 FITNESS:  0.0318570006127451\n",
      "GEN:  172 FITNESS:  0.0318570006127451\n",
      "GEN:  173 FITNESS:  0.0318570006127451\n",
      "GEN:  174 FITNESS:  0.0318570006127451\n",
      "GEN:  175 FITNESS:  0.0318570006127451\n",
      "GEN:  176 FITNESS:  0.0318570006127451\n",
      "GEN:  177 FITNESS:  0.0318570006127451\n",
      "GEN:  178 FITNESS:  0.0318570006127451\n",
      "GEN:  179 FITNESS:  0.0318570006127451\n",
      "GEN:  180 FITNESS:  0.0318570006127451\n",
      "GEN:  181 FITNESS:  0.0318570006127451\n",
      "GEN:  182 FITNESS:  0.0318570006127451\n",
      "GEN:  183 FITNESS:  0.0318570006127451\n",
      "GEN:  184 FITNESS:  0.0318570006127451\n",
      "GEN:  185 FITNESS:  0.0318570006127451\n",
      "GEN:  186 FITNESS:  0.0318570006127451\n",
      "GEN:  187 FITNESS:  0.0318570006127451\n",
      "GEN:  188 FITNESS:  0.0318570006127451\n",
      "GEN:  189 FITNESS:  0.0318570006127451\n",
      "GEN:  190 FITNESS:  0.0318570006127451\n",
      "GEN:  191 FITNESS:  0.0318570006127451\n",
      "GEN:  192 FITNESS:  0.0318570006127451\n",
      "GEN:  193 FITNESS:  0.0318570006127451\n",
      "GEN:  194 FITNESS:  0.0318570006127451\n",
      "GEN:  195 FITNESS:  0.0318570006127451\n",
      "GEN:  196 FITNESS:  0.0318570006127451\n",
      "GEN:  197 FITNESS:  0.0318570006127451\n",
      "GEN:  198 FITNESS:  0.0318570006127451\n",
      "GEN:  199 FITNESS:  0.0318570006127451\n",
      "GEN:  200 FITNESS:  0.0318570006127451\n",
      "GEN:  201 FITNESS:  0.0318570006127451\n",
      "GEN:  202 FITNESS:  0.0318570006127451\n",
      "GEN:  203 FITNESS:  0.0318570006127451\n",
      "GEN:  204 FITNESS:  0.0318570006127451\n",
      "GEN:  205 FITNESS:  0.0318570006127451\n",
      "GEN:  206 FITNESS:  0.0318570006127451\n",
      "GEN:  207 FITNESS:  0.0318570006127451\n",
      "GEN:  208 FITNESS:  0.0318570006127451\n",
      "GEN:  209 FITNESS:  0.0318570006127451\n",
      "GEN:  210 FITNESS:  0.0318570006127451\n",
      "GEN:  211 FITNESS:  0.0318570006127451\n",
      "GEN:  212 FITNESS:  0.0318570006127451\n",
      "GEN:  213 FITNESS:  0.0318570006127451\n",
      "GEN:  214 FITNESS:  0.0318570006127451\n",
      "GEN:  215 FITNESS:  0.0318570006127451\n",
      "GEN:  216 FITNESS:  0.0318570006127451\n",
      "GEN:  217 FITNESS:  0.0318570006127451\n",
      "GEN:  218 FITNESS:  0.0318570006127451\n",
      "GEN:  219 FITNESS:  0.0318570006127451\n",
      "GEN:  220 FITNESS:  0.0318570006127451\n",
      "GEN:  221 FITNESS:  0.0318570006127451\n",
      "GEN:  222 FITNESS:  0.0318570006127451\n",
      "GEN:  223 FITNESS:  0.0318570006127451\n",
      "GEN:  224 FITNESS:  0.034172746246936274\n",
      "GEN:  225 FITNESS:  0.034172746246936274\n",
      "GEN:  226 FITNESS:  0.034172746246936274\n",
      "GEN:  227 FITNESS:  0.034172746246936274\n",
      "GEN:  228 FITNESS:  0.034172746246936274\n",
      "GEN:  229 FITNESS:  0.034172746246936274\n",
      "GEN:  230 FITNESS:  0.034172746246936274\n",
      "GEN:  231 FITNESS:  0.034172746246936274\n",
      "GEN:  232 FITNESS:  0.034172746246936274\n",
      "GEN:  233 FITNESS:  0.034172746246936274\n",
      "GEN:  234 FITNESS:  0.034172746246936274\n",
      "GEN:  235 FITNESS:  0.034172746246936274\n"
     ]
    }
   ],
   "source": [
    "def run_trial(gene,max_t):\n",
    "    dt=0.1\n",
    "    t=0\n",
    "    done=False\n",
    "    r_sum = 0\n",
    "    o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "    step = 0\n",
    "    sensor.set_genes(gene) #set the gene of the robot\n",
    "    while not done and t<=max_t: #loop till sturdy or out of time\n",
    "        tactile_input=np.reshape(o['tactile'],(128,128))\n",
    "        a=sensor.forward(tactile_input)[0] #push through tactile input into agent\n",
    "        # step the environment\n",
    "        o, r, d, info = env.step(a) #step through environment\n",
    "        fit=fitness(tactile_input)\n",
    "        if fit>=0.5: #if it is sturdy\n",
    "            done=True\n",
    "        t+=dt #increase by timestep\n",
    "    return fit, env.render() #we care about the last fitnesses as it should be sturdy\n",
    "\n",
    "def run_microbial(population,generations): #microbial algorithm trial\n",
    "    fitnesses=[0]\n",
    "    rendered=[]\n",
    "    for i in range(generations):\n",
    "        print(\"GEN: \",i,\"FITNESS: \",fitnesses[-1])\n",
    "        #select neighbouring genes\n",
    "        ind_1 = rnd.randint(0,len(population)-1)\n",
    "        ind_2=ind_1+1\n",
    "        if ind_2 >= len(population): ind_2=ind_1-1\n",
    "        #get two random positions\n",
    "        gene1=population[ind_1]\n",
    "        gene2=population[ind_2]\n",
    "        #run trials for 20 seconds in sim time\n",
    "        fit1,r1=run_trial(gene1,5)\n",
    "        fit2,r2=run_trial(gene2,5)\n",
    "        fitnesses.append(max([fitnesses[-1],fit1,fit2]))\n",
    "        #selection\n",
    "        if fit1>fit2:\n",
    "            gene2=copy.deepcopy((gene1)) #crossover\n",
    "            population[ind_2]=copy.deepcopy(crossover(gene2,mutation(gene1)))\n",
    "            rendered.append(copy.deepcopy(r1))\n",
    "        elif fit2>fit1:\n",
    "            gene1=copy.deepcopy((gene2)) #crossover\n",
    "            population[ind_1]=copy.deepcopy(crossover(gene1,mutation(gene2)))\n",
    "            rendered.append(copy.deepcopy(r2))\n",
    "    return fitnesses, rendered\n",
    "GENERATIONS=250\n",
    "f,r=run_microbial(gen_population(),GENERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rendered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rendered\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rendered' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Best touch\")\n",
    "plt.imshow(r[-1])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
