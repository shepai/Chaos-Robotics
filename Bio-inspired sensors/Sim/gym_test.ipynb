{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the tactile gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jan 20 2023 16:26:58\n"
     ]
    }
   ],
   "source": [
    "from tactile_gym.rl_envs.demo_rl_env_base import demo_rl_env\n",
    "from tactile_gym.rl_envs.exploration.edge_follow.edge_follow_env import EdgeFollowEnv\n",
    "from scipy import signal\n",
    "from scipy import misc\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import random as rnd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up some variables of what we want within the envirnment. \n",
    "\n",
    "Number of iterations is how long our training loop will be\n",
    "\n",
    "max_steps is how many steps each iteration can ake within the environment\n",
    "\n",
    "show_gui allows us to view or not view a gui showing whats going on\n",
    "\n",
    "This is the same with show tactle\n",
    "\n",
    "Rendering is required for showing the gui - it is quicker without\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = int(0)\n",
    "num_iter = 100\n",
    "max_steps = 250\n",
    "show_gui = True\n",
    "show_tactile = False\n",
    "render = False\n",
    "print_info = False\n",
    "image_size = [128, 128]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=3\n",
      "argv[0] = --unused\n",
      "argv[1] = \n",
      "argv[2] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Mesa/X.org\n",
      "GL_RENDERER=llvmpipe (LLVM 12.0.0, 256 bits)\n",
      "GL_VERSION=4.5 (Core Profile) Mesa 21.2.6\n",
      "GL_SHADING_LANGUAGE_VERSION=4.50\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.5 (Core Profile) Mesa 21.2.6\n",
      "Vendor = Mesa/X.org\n",
      "Renderer = llvmpipe (LLVM 12.0.0, 256 bits)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Mesa/X.org\n",
      "ven = Mesa/X.org\n"
     ]
    }
   ],
   "source": [
    "env_modes = {\n",
    "    # which dofs can have movement\n",
    "    \"movement_mode\": \"xy\",\n",
    "\n",
    "    # specify arm\n",
    "    \"arm_type\": \"ur5\",\n",
    "\n",
    "    # specify tactile sensor\n",
    "    \"tactile_sensor_name\": \"tactip\",\n",
    "    # \"tactile_sensor_name\": \"digit\",\n",
    "    # \"tactile_sensor_name\": \"digitac\",\n",
    "\n",
    "    # the type of control used\n",
    "    # \"control_mode\": \"TCP_position_control\",\n",
    "    'control_mode': 'TCP_velocity_control',\n",
    "\n",
    "    # add variation to embed distance to optimise for\n",
    "    # warning, don't use rand height when controlling z unless\n",
    "    # including embed distance in observation\n",
    "    # 'noise_mode':'fixed_height',\n",
    "    \"noise_mode\": \"rand_height\",\n",
    "\n",
    "    # which observation type to return\n",
    "    'observation_mode': 'oracle',\n",
    "    \"observation_mode\": \"tactile\",\n",
    "    # 'observation_mode':'visual',\n",
    "    # 'observation_mode':'visuotactile',\n",
    "\n",
    "    # which reward type to use (currently only dense)\n",
    "    \"reward_mode\": \"dense\"\n",
    "    # 'reward_mode':'sparse'\n",
    "}\n",
    "env = EdgeFollowEnv(\n",
    "    max_steps=max_steps,\n",
    "    env_modes=env_modes,\n",
    "    show_gui=show_gui,\n",
    "    show_tactile=show_tactile,\n",
    "    image_size=image_size\n",
    ")\n",
    "\n",
    "# set seed for deterministic results\n",
    "env.seed(seed)\n",
    "env.action_space.np_random.seed(seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate GUI is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create controllable parameters on GUI\n",
    "action_ids = []\n",
    "min_action = env.min_action\n",
    "max_action = env.max_action\n",
    "if show_gui:\n",
    "\n",
    "    if env_modes[\"movement_mode\"] == \"xy\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "\n",
    "    elif env_modes[\"movement_mode\"] == \"xyz\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dZ\", min_action, max_action, 0))\n",
    "\n",
    "    elif env_modes[\"movement_mode\"] == \"xyRz\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dRz\", min_action, max_action, 0))\n",
    "\n",
    "    elif env_modes[\"movement_mode\"] == \"xyzRz\":\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dX\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dY\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dZ\", min_action, max_action, 0))\n",
    "        action_ids.append(env._pb.addUserDebugParameter(\"dRz\", min_action, max_action, 0))\n",
    "\n",
    "# run the control loop\n",
    "#demo_rl_env(env, num_iter, action_ids, show_gui, show_tactile, render, print_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make model for evolution, this uses a convolutional neural network. Weights are assigned randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_Conv2D:\n",
    "    def __init__(self, num_input, layers, num_output):\n",
    "        assert type(layers)==type([]), \"Error with layers, give array of the number of layers\"\n",
    "        self.num_input = num_input  #set input number\n",
    "        self.num_output = num_output #set ooutput number\n",
    "        self.hidden=[]\n",
    "        last=num_input\n",
    "        self.num_genes=0\n",
    "        for layer in layers:\n",
    "            self.hidden.append(layer)\n",
    "            self.num_genes+=(last * layer)\n",
    "            last=layer\n",
    "        self.num_genes +=(self.hidden[-1]*num_output)+num_output\n",
    "        self.weights = None\n",
    "        self.hidden_weights=None\n",
    "        self.bias = None\n",
    "        print(\"Auto\",self.num_genes)\n",
    "    def set_genes(self, gene):\n",
    "        weight_idxs = self.num_input * self.hidden[0] #size of weights to hidden\n",
    "        current=weight_idxs\n",
    "        weights_idxs=[current] #start with end of last\n",
    "        for i in range(len(self.hidden)-1):\n",
    "            current+=self.hidden[i]*self.hidden[i+1] #calculate next idx for each layer\n",
    "            weights_idxs.append(current)\n",
    "        bias_idxs=None\n",
    "        weights_idxs.append(self.hidden[-1] * self.num_output + weights_idxs[-1]) #add last layer heading to output\n",
    "        bias_idxs = weights_idxs[-1]+ self.num_output #sizes of biases\n",
    "        w = gene[0 : weight_idxs].reshape(self.hidden[0], self.num_input)   #merge genes\n",
    "        ws=[]\n",
    "        for i in range(len(self.hidden)-1):\n",
    "            ws.append(gene[weights_idxs[i] : weights_idxs[i+1]].reshape(self.hidden[i+1], self.hidden[i]))\n",
    "        ws.append(gene[weights_idxs[-2] : weights_idxs[-1]].reshape(self.num_output, self.hidden[-1]))\n",
    "        b = gene[weights_idxs[-1]: bias_idxs].reshape(self.num_output,) #merge genes\n",
    "\n",
    "        self.weights = torch.from_numpy(w) #assign weights\n",
    "        self.hidden_weights=[]\n",
    "        for w in ws:\n",
    "            self.hidden_weights.append(torch.from_numpy(w))\n",
    "        self.bias = torch.from_numpy(b) #assign biases\n",
    "\n",
    "    def forward(self, x):\n",
    "        #create conv layer\n",
    "        scharr = np.array([[ -3-3, 0-10,  +3 -3],\n",
    "                   [-10+0, 0+ 0, +10 +0],\n",
    "                   [ -3+3, 0+10,  +3 +3]]) # Gx + j*Gy\n",
    "        x= signal.convolve2d(x, scharr, boundary='symm', mode='same')   \n",
    "        x=x.flatten()\n",
    "        x=torch.tensor(x[:,np.newaxis]).float()  \n",
    "        #x = torch.tensor(np.dot(self.weights.float(),x).flatten()).float()\n",
    "        #run through forward layers\n",
    "        x = torch.mm(x.T, self.weights.T.float()) #first layer\n",
    "\n",
    "        for i in range(len(self.hidden_weights)-1):\n",
    "            x = torch.mm(x,self.hidden_weights[i].T.float()) #second layer\n",
    "        return torch.mm(x,self.hidden_weights[-1].T.float()) + self.bias #third layer\n",
    "    \n",
    "    def get_action(self, x,vec):\n",
    "        vec=np.array(vec)\n",
    "        vectors=[(1,1),(1,0),(0,1),(-1,-1),(-1,0),(0,-1),(-1,1),(1,-1)] #possible moves\n",
    "        arr=list(self.forward(x,vec)[0])\n",
    "        ind=np.argmax(arr)\n",
    "        return vectors[ind]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an agent and population of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto 1646262\n",
      "[1.161567 2.453173 3.416006 ... -3.188365 3.648837 -0.067102]\n"
     ]
    }
   ],
   "source": [
    "sensor=Agent_Conv2D(128*128,[100,60,30],2)\n",
    "size=sensor.num_genes\n",
    "def gen_population(pop_size=100):\n",
    "    population=np.random.normal(0,3,(pop_size,size))\n",
    "    return population\n",
    "\"\"\"for i in range(pop_size):\n",
    "    population[i]+=(size))\"\"\"\n",
    "\n",
    "print(gen_population()[0])\n",
    "population=gen_population()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitness function and mutation of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(tactile):\n",
    "    #lets say we want to maximize the lighter pixels \n",
    "    all=np.sum(tactile)\n",
    "    all=(all/255)/(128*128)\n",
    "    return all\n",
    "def mutation(gene, mean=0, std=0.5,size=100):\n",
    "    assert size<len(gene)\n",
    "    n=rnd.randint(0,len(gene)-size-1)\n",
    "    array=np.random.normal(mean,std,size=size)\n",
    "    gene = gene[n:n+size] + array #mutate the gene via normal \n",
    "    # constraint\n",
    "    gene[gene >4] = 4\n",
    "    gene[gene < -4] = -4\n",
    "    return gene\n",
    "\n",
    "def crossover(loser, winner, p_crossover=0.5): #provide a crossover function\n",
    "    for i,gene in enumerate(winner):\n",
    "      if rnd.random() <= p_crossover:\n",
    "        loser[i] = winner[i]\n",
    "    return loser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a loop with a genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# collection loop\\nGENERATIONS=1000\\nr_sum = 0\\no, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\\nstep = 0\\nfor i in range(GENERATIONS):\\n        sensor.set_genes(population[0])\\n        tactile_input=np.reshape(o[\\'tactile\\'],(128,128))\\n        a=sensor.forward(tactile_input)[0] #push through tactile input into agent\\n        # step the environment\\n        o, r, d, info = env.step(a)\\n    \\n        # render visual + tactile observation\\n        if render:\\n            render_img = env.render()\\n        #print(o[\\'tactile\\'])\\n        r_sum += r\\n        step += 1\\n\\n        q_key = ord(\"q\")\\n        r_key = ord(\"r\")\\n        keys = env._pb.getKeyboardEvents()\\n        if q_key in keys and keys[q_key] & env._pb.KEY_WAS_TRIGGERED:\\n            exit()\\n        elif r_key in keys and keys[r_key] & env._pb.KEY_WAS_TRIGGERED:\\n            d = True\\n\\nprint(\"Total Reward: \", r_sum)\\n    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# collection loop\n",
    "GENERATIONS=1000\n",
    "r_sum = 0\n",
    "o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "step = 0\n",
    "for i in range(GENERATIONS):\n",
    "        sensor.set_genes(population[0])\n",
    "        tactile_input=np.reshape(o['tactile'],(128,128))\n",
    "        a=sensor.forward(tactile_input)[0] #push through tactile input into agent\n",
    "        # step the environment\n",
    "        o, r, d, info = env.step(a)\n",
    "    \n",
    "        # render visual + tactile observation\n",
    "        if render:\n",
    "            render_img = env.render()\n",
    "        #print(o['tactile'])\n",
    "        r_sum += r\n",
    "        step += 1\n",
    "\n",
    "        q_key = ord(\"q\")\n",
    "        r_key = ord(\"r\")\n",
    "        keys = env._pb.getKeyboardEvents()\n",
    "        if q_key in keys and keys[q_key] & env._pb.KEY_WAS_TRIGGERED:\n",
    "            exit()\n",
    "        elif r_key in keys and keys[r_key] & env._pb.KEY_WAS_TRIGGERED:\n",
    "            d = True\n",
    "\n",
    "print(\"Total Reward: \", r_sum)\n",
    "    \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the microbial GA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEN:  0 FITNESS:  0\n"
     ]
    }
   ],
   "source": [
    "def run_trial(gene,max_t):\n",
    "    dt=0.01\n",
    "    t=0\n",
    "    done=False\n",
    "    r_sum = 0\n",
    "    o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "    step = 0\n",
    "    sensor.set_genes(gene) #set the gene of the robot\n",
    "    while not done or t>=max_t: #loop till sturdy or out of time\n",
    "        tactile_input=np.reshape(o['tactile'],(128,128))\n",
    "        a=sensor.forward(tactile_input)[0] #push through tactile input into agent\n",
    "        # step the environment\n",
    "        o, r, d, info = env.step(a) #step through environment\n",
    "        fit=fitness(tactile_input)\n",
    "        if fit>=0.9: #if it is sturdy\n",
    "            done=True\n",
    "        t+=dt #increase by timestep\n",
    "    return fit\n",
    "\n",
    "def run_microbial(population,generations): #microbial algorithm trial\n",
    "    fitnesses=[0]\n",
    "    for i in range(generations):\n",
    "        print(\"GEN: \",i,\"FITNESS: \",fitnesses[-1])\n",
    "        #select neighbouring genes\n",
    "        ind_1 = rnd.randint(0,len(population)-1)\n",
    "        ind_2=ind_1+1\n",
    "        if ind_2 >= len(population): ind_2=ind_1-1\n",
    "        #get two random positions\n",
    "        gene1=population[ind_1]\n",
    "        gene2=population[ind_2]\n",
    "        #run trials for 20 seconds in sim time\n",
    "        fit1=run_trial(gene1,20)\n",
    "        fit2=run_trial(gene2,20)\n",
    "        fitnesses.append(max([fitnesses[-1],fit1,fit2]))\n",
    "        #selection\n",
    "        if fit1>fit2:\n",
    "            gene2=copy.deepcopy((gene1)) #crossover\n",
    "            population[ind_2]=copy.deepcopy(crossover(gene2,mutation(gene1)))\n",
    "        elif fit2>fit1:\n",
    "            gene1=copy.deepcopy((gene2)) #crossover\n",
    "            population[ind_1]=copy.deepcopy(crossover(gene1,mutation(gene2)))\n",
    "    return fitnesses\n",
    "GENERATIONS=500\n",
    "run_microbial(gen_population(),GENERATIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
