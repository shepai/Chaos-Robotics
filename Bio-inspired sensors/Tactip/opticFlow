
# import the opencv library
import cv2 as cv
import numpy as np
import math
def adaptive(img):
    frame=np.copy(img)
    threshold=200
    sum=0
    while sum<21000000:
        frame[frame>threshold]=255
        frame[frame<=threshold]=0
        sum=np.sum(frame)
        if sum>22000000:
            threshold+=1
        elif sum<22000000:
            threshold-=1
        frame=np.copy(img)
    frame[frame>threshold]=255
    frame[frame<=threshold]=0
    return frame

def removeBlob(im):
    # find all of the connected components (white blobs in your image).
    # im_with_separated_blobs is an image where each detected blob has a different pixel value ranging from 1 to nb_blobs - 1.
    nb_blobs, im_with_separated_blobs, stats, _ = cv.connectedComponentsWithStats(im)
    # stats (and the silenced output centroids) gives some information about the blobs. See the docs for more information. 
    # here, we're interested only in the size of the blobs, contained in the last column of stats.
    sizes = stats[:, -1]
    # the following lines result in taking out the background which is also considered a component, which I find for most applications to not be the expected output.
    # you may also keep the results as they are by commenting out the following lines. You'll have to update the ranges in the for loop below. 
    sizes = sizes[1:]
    nb_blobs -= 1

    # minimum size of particles we want to keep (number of pixels).
    # here, it's a fixed value, but you can set it as you want, eg the mean of the sizes or whatever.
    min_size = 250

    # output image with only the kept components
    im_result = np.zeros_like(im_with_separated_blobs)
    im_result_with = np.zeros_like(im_with_separated_blobs)
    # for every component in the image, keep it only if it's above min_size
    for blob in range(nb_blobs):
        if sizes[blob] >= min_size:
            # see description of im_with_separated_blobs above
            im_result_with[im_with_separated_blobs == blob + 1] = 255#
        if sizes[blob] <= min_size:
            # see description of im_with_separated_blobs above
            im_result[im_with_separated_blobs == blob + 1] = 255#
    #difference = cv.subtract(im.astype(np.uint8), im_result.astype(np.uint8))
    # color the mask red
    #ret, mask = cv.threshold(difference, 0, 255,cv.THRESH_BINARY_INV |cv.THRESH_OTSU)
    #difference[mask != 255] = [255]

    return im_result_with,im_result

def get_processed(frame):
    #make gray and preprocess the binary threshold
    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    frame_gray=adaptive(frame_gray)
    #remove the blobs
    to_Show,spots=removeBlob(frame_gray)
    to_Show=to_Show.astype(np.uint8)
    spots=spots.astype(np.uint8)
    #replace parts
    inds=np.argwhere(to_Show == 255)
    frame[inds[:,0],inds[:,1]]=[80,80,80]
    inds=np.argwhere(spots == 255)
    frame[inds[:,0],inds[:,1]]=[255,255,255]
    return frame

# define a video capture object
cap = cv.VideoCapture(0)
  

# params for ShiTomasi corner detection
feature_params = dict( maxCorners = 100,
                       qualityLevel = 0.1,
                       minDistance = 7,
                       blockSize = 7 )
# Parameters for lucas kanade optical flow
lk_params = dict( winSize  = (15, 15),
                  maxLevel = 10,
                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.1))
# Create some random colors
color = np.random.randint(0, 255, (100, 3))
# Take first frame and find corners in it
ret, old_frame = cap.read()
old_frame=get_processed(old_frame)
#old_frame=old_frame[125:404,188:408]
good_new=[]
old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)
p0=np.argwhere(old_gray == 255)
p0=p0.astype(np.float32)
print(len(p0))
d=10

a,b = np.tril_indices(p0.shape[0], -1)
diss = np.linalg.norm(p0[b] - p0[a], axis=1)

near = p0[(np.concatenate([b[diss < d], a[diss < d]]))]
import matplotlib.pyplot as plt

plt.scatter(near[:,0], near[:,1])
plt.show()
print(len(near))
s=p0.shape
p0=p0.reshape([s[0],1,s[1]])
#np.save("./calibrate",p0)
#p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)

exit()
#p0 = cv.cornerMinEigenVal(old_gray, blockSize=7,ksize = 3)
# Create a mask image for drawing purposes
mask = np.zeros_like(old_frame)

#print(p0)

begin=[]

while(1):
    #vectors=[]
    ret, frame = cap.read()
    if not ret:
        print('No frames grabbed!')
        break
    frame=get_processed(frame)
    
    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    #binary
    #frame_gray[frame_gray>245]=255
    #frame_gray[frame_gray<=245]=0
    # calculate optical flow
    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)
    # Select good points
    if p1 is not None:
        good_new = p1[st==1]
        good_old = p0[st==1]
    # draw the tracks
    started=False
    if len(begin)==0: #has not been chosen
        started=True
    if len(begin)!=len(good_new):
        begin=[]
        started=True
    mask = np.zeros_like(old_frame) 
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel()
        c, d = old.ravel()
        #mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)
        #mask = cv.arrowedLine(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)
        if i<len(color):
            frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)
            if started:
                begin.append([c, d])
    sumof=0
    sumofsq=0
    for i in range(len(begin)):
        if i<len(begin) and i<len(good_new):
            vy=begin[i][1]-good_new[i][1]
            vx=begin[i][0]-good_new[i][0]
            #vectors.append([vx,vy])
            sumof+= math.sqrt((vy**2) + (vx**2))
            sumofsq+= ((vy**2) + (vx**2))
            if math.sqrt((vy**2) + (vx**2))> 1.5:
                mask = cv.arrowedLine(mask, (int(begin[i][0]), int( begin[i][1])), (int(good_new[i][0]), int(good_new[i][1])), color[i].tolist(), 2)
    average=sumof/min(len(begin),len(good_new))
    std=math.sqrt((sumofsq/min(len(begin),len(good_new)))-(average**2))
    #print(average/std)
    #img = cv.add(frame, mask)
    cv.imshow('frame', frame)
    cv.imshow('displacement', mask)
    k = cv.waitKey(1) & 0xff
    if k == ord('q'):
        break
    elif k == ord('r') or (average/std<1):
        begin=[]
        img = frame.copy()
        mask = np.zeros_like(old_frame)
        old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)
        #p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)
        
        print("reset")

    # Now update the previous frame and previous points
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)
cv.destroyAllWindows()